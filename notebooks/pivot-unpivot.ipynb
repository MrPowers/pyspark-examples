{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d970f0e-d08a-438d-ba05-02c99f8b518b",
   "metadata": {},
   "source": [
    "# PySpark Pivot & Unpivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c6873f-1b8c-45b8-84ee-c5bdc6ea1a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c4ec5e3-3774-4463-ad65-9b52f90c7b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/07 10:19:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/08/07 10:19:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/08/07 10:19:38 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/08/07 10:19:38 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"demo\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f774a0-8d4d-4e29-acd0-37e2be9678a8",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad62334e-6571-441e-b4fe-5a87908ffa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = spark.createDataFrame(\n",
    "    [\n",
    "        [\"Bruce\", \"Lee\", \"China\"],\n",
    "        [\"Tom\", \"Hanks\", \"USA\"],\n",
    "        [\"Diego\", \"Luna\", \"Mexico\"],\n",
    "        [\"Samuel\", \"Jackson\", \"USA\"],\n",
    "    ],\n",
    "    [\"first_name\", \"last_name\", \"country\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d77d2a8f-36fc-4627-b49a-30e178cadcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|first_name|last_name|country|\n",
      "+----------+---------+-------+\n",
      "|     Bruce|      Lee|  China|\n",
      "|       Tom|    Hanks|    USA|\n",
      "|     Diego|     Luna| Mexico|\n",
      "|    Samuel|  Jackson|    USA|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actors.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a779b10-fc4e-49b9-83e7-076376a48f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+------+----+\n",
      "|country|Bruce|Diego|Samuel| Tom|\n",
      "+-------+-----+-----+------+----+\n",
      "|  China|    1| null|  null|null|\n",
      "|    USA| null| null|     1|   1|\n",
      "| Mexico| null|    1|  null|null|\n",
      "+-------+-----+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countries = actors.groupBy(\"country\").pivot(\"first_name\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723939ab-8ff8-407a-bf15-ad5a781b74de",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bed34a64-06fa-4cac-86cb-72ae6c213a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        [\"x\", \"h\", 1],\n",
    "        [\"x\", \"i\", 2],\n",
    "        [\"x\", \"h\", 3],\n",
    "        [\"y\", \"i\", 4],\n",
    "        [\"y\", \"i\", 1],\n",
    "    ],\n",
    "    [\"a\", \"b\", \"c\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "951b42a3-119c-45fb-bbbc-047b3e12108f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "|  a|  b|  c|\n",
      "+---+---+---+\n",
      "|  x|  h|  1|\n",
      "|  x|  i|  2|\n",
      "|  x|  h|  3|\n",
      "|  y|  i|  4|\n",
      "|  y|  i|  1|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9702983e-0040-4736-ad64-c1538057fa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "|  a|   h|  i|\n",
      "+---+----+---+\n",
      "|  x|   4|  2|\n",
      "|  y|null|  5|\n",
      "+---+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivoted = df.groupBy(\"a\").pivot(\"b\").sum(\"c\")\n",
    "pivoted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10036f49-6b9c-4142-bed1-e06d30a1ab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "|  a|  b|   c|\n",
      "+---+---+----+\n",
      "|  x|  h|   4|\n",
      "|  x|  i|   2|\n",
      "|  y|  h|null|\n",
      "|  y|  i|   5|\n",
      "+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivoted.unpivot(\"a\", [\"h\", \"i\"], \"b\", \"c\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22858d46-5936-481a-b31f-99e52d1a311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-341",
   "language": "python",
   "name": "pyspark-341"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
