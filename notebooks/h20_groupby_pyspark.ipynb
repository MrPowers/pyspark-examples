{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3469f2b-1914-45f6-8f46-dccbed3477fe",
   "metadata": {},
   "source": [
    "# h2o groupby queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc4eebea-0b15-4d51-bddc-8918bdd13c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import delta\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from delta import configure_spark_with_delta_pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db0598b0-298a-4f2b-a743-e3ef325f5987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/matthew.powers/opt/miniconda3/envs/pyspark-340-delta-240/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/matthew.powers/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/matthew.powers/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f79fb089-5d94-4411-9dc2-7f86ace3e5ce;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 104ms :: artifacts dl 5ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f79fb089-5d94-4411-9dc2-7f86ace3e5ce\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/3ms)\n",
      "23/11/14 07:48:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "builder = (\n",
    "    pyspark.sql.SparkSession.builder.appName(\"MyApp\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.executor.memory\", \"10G\")\n",
    "    .config(\"spark.driver.memory\", \"25G\")\n",
    "    .config(\n",
    "        \"spark.sql.catalog.spark_catalog\",\n",
    "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "    )\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"2\")\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd8774e-9a36-4e66-a0d6-4866d3ab22af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").load(f\"{Path.home()}/data/deltalake/G1_1e9_1e2_0_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8c63780-212f-4173-a715-50057394e3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------------+---+---+-------+---+---+---------+\n",
      "|  id1|  id2|         id3|id4|id5|    id6| v1| v2|       v3|\n",
      "+-----+-----+------------+---+---+-------+---+---+---------+\n",
      "|id015|id010|id0000896846| 10|  1|5773276|  1|  1|33.170577|\n",
      "|id017|id017|id0007133323| 71| 14|5476891|  3|  2|34.800229|\n",
      "|id016|id030|id0002048672| 55| 35|4861331|  1|  3|32.064864|\n",
      "+-----+-----+------------+---+---+-------+---+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from {df} limit 3\", df=df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b08448-57d8-45c7-9d6d-e8b4d8ab41a8",
   "metadata": {},
   "source": [
    "## Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03ef2256-5c59-4229-995a-639a11a44ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/14 07:49:11 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 9:======================================================>(185 + 2) / 187]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|  id1|      v1|\n",
      "+-----+--------+\n",
      "|id016|30003304|\n",
      "|id074|30006309|\n",
      "|id070|29990210|\n",
      "|id054|30011978|\n",
      "|id053|29992360|\n",
      "|id056|29987234|\n",
      "|id057|29991822|\n",
      "|id003|30003365|\n",
      "|id001|30009448|\n",
      "|id015|30006177|\n",
      "|id017|29995061|\n",
      "|id018|29992469|\n",
      "|id014|29998476|\n",
      "|id072|30003522|\n",
      "|id071|29998357|\n",
      "|id073|30006820|\n",
      "|id055|30009993|\n",
      "|id004|30015990|\n",
      "|id002|29996534|\n",
      "|id005|29993888|\n",
      "+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select id1, sum(v1) as v1 from {df} group by id1\", df=df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78d7c9e6-b261-4615-ab8e-bee2468d862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select id1, sum(v1) as v1 from {df} group by id1\", df=df).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cd70d4-554a-411a-872a-8f36b8b5a2ed",
   "metadata": {},
   "source": [
    "## Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c49b430d-0566-4b99-a148-496546631fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:=====================================================>(185 + 2) / 187]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+\n",
      "|  id1|  id2|    v1|\n",
      "+-----+-----+------+\n",
      "|id016|id026|298873|\n",
      "|id014|id009|299719|\n",
      "|id017|id041|298918|\n",
      "|id015|id100|299767|\n",
      "|id016|id014|299652|\n",
      "|id015|id018|299426|\n",
      "|id014|id022|299753|\n",
      "|id014|id044|300032|\n",
      "|id015|id079|298299|\n",
      "|id014|id025|300019|\n",
      "|id014|id075|301299|\n",
      "|id016|id079|300597|\n",
      "|id017|id004|301294|\n",
      "|id016|id061|299681|\n",
      "|id015|id032|298705|\n",
      "|id017|id036|298451|\n",
      "|id017|id068|298285|\n",
      "|id015|id072|300308|\n",
      "|id017|id064|298988|\n",
      "|id015|id085|301252|\n",
      "+-----+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select id1, id2, sum(v1) as v1 from {df} group by id1, id2\", df=df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce0b2358-c931-4ac8-8acd-301480daad78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select id1, id2, sum(v1) as v1 from {df} group by id1, id2\", df=df).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a5ea8b-b77a-4d28-8b85-d96712a3414d",
   "metadata": {},
   "source": [
    "## Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed08e8bd-fa30-46c4-8089-8751282d8fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+------------------+\n",
      "|         id3| v1|                v3|\n",
      "+------------+---+------------------+\n",
      "|id0002654924|330|49.091885935185196|\n",
      "|id0001975574|329|48.816218894230765|\n",
      "|id0002470600|324|53.640876399999996|\n",
      "|id0001698780|285|45.204360193548375|\n",
      "|id0000058673|291|51.325111176470614|\n",
      "|id0003895227|358| 49.58640469565216|\n",
      "|id0005293826|295| 52.53704746315788|\n",
      "|id0007581630|300|48.697405603960384|\n",
      "|id0000651978|389| 49.91647398305082|\n",
      "|id0003454065|274|51.122333543478256|\n",
      "|id0001755020|342| 50.57228290434781|\n",
      "|id0005409186|287| 53.28691733333334|\n",
      "|id0005802677|310| 48.31412209708738|\n",
      "|id0009759301|308|52.288704642857134|\n",
      "|id0005675043|362| 47.65540899115044|\n",
      "|id0008654924|258| 52.24759900000001|\n",
      "|id0000248674|302|49.937610443298986|\n",
      "|id0005200803|249| 43.05500375000001|\n",
      "|id0000784417|289| 48.57986409183674|\n",
      "|id0007793617|324|50.550142678899086|\n",
      "+------------+---+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select id3, sum(v1) as v1, mean(v3) as v3 from {df} group by id3\", df=df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48197bf4-af73-40eb-9684-5f9dfab027ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select id3, sum(v1) as v1, mean(v3) as v3 from {df} group by id3\", df=df).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090cfc0b-da5f-465f-a6e0-e3777fe5b910",
   "metadata": {},
   "source": [
    "## Query 3 Modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd92d4bc-e91e-4098-a408-c50cc70d40ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spark.sql(\"select id3, sum(v1) as v1, mean(v3) as v3 from {df} group by id3 order by v1 desc limit 3\", df=df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebe84b1-24a3-469d-9851-083987fc9ad2",
   "metadata": {},
   "source": [
    "## Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34938385-11af-4263-9f61-d081e950c489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:===============================================>     (169 + 10) / 187]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+------------------+------------------+\n",
      "|id4|                v1|                v2|                v3|\n",
      "+---+------------------+------------------+------------------+\n",
      "| 55|2.9998246661254955| 8.000023904618372|49.996973064034094|\n",
      "| 29| 3.000572167759587| 7.999551868607876| 50.00342673344333|\n",
      "| 82|2.9995379061458483| 7.999010613158845| 50.00021376928316|\n",
      "| 87| 3.000169991381437| 8.000503174489053|50.011425763409626|\n",
      "| 30|2.9985825421677204|7.9989537573132985| 50.00214866288746|\n",
      "| 33|2.9999564146969644|7.9998203605744145| 50.00827978135219|\n",
      "| 19| 2.999691681710651| 7.998959063016616| 49.99534693159616|\n",
      "|  4| 2.999351427953455|  8.00024738933752| 50.00297873205454|\n",
      "| 94| 2.999753562664744| 7.999774665861878| 50.00962994793641|\n",
      "| 61| 3.000324935027996| 7.999546751139773|  49.9995310819004|\n",
      "| 42|3.0005378493745725| 8.003788547788687| 50.00666532597359|\n",
      "| 91| 3.000607368929785|  7.99814300074044| 50.01352919169919|\n",
      "| 81| 2.999849930119025| 7.999589682350752| 49.99841869137998|\n",
      "|  2| 3.000483387734874| 8.000686324567909|50.018227437876455|\n",
      "| 79| 3.000387234060432| 7.999028063515589| 50.00669293991243|\n",
      "| 18| 3.000222023312448| 8.000932597922782| 50.00384673638313|\n",
      "| 12| 2.999839676400366|  8.00007011032024|49.999889884748214|\n",
      "| 44|3.0004836689000896| 7.999020962952082|50.003574675633864|\n",
      "| 88| 3.000599563486584| 8.000519568358287| 50.00847446508867|\n",
      "| 89|3.0004350572773753| 7.996940600433038| 50.00298800201348|\n",
      "+---+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select id4, mean(v1) as v1, mean(v2) as v2, mean(v3) as v3 from {df} group by id4\", df=df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a8e6877-a5fd-4ec0-a84a-47dc888c3677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select id4, mean(v1) as v1, mean(v2) as v2, mean(v3) as v3 from {df} group by id4\", df=df).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec42c00-1a61-4f87-9005-0e7d8faed2fc",
   "metadata": {},
   "source": [
    "## Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0e2e968-f3c8-4e3f-ac5b-4285236d6adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 66:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+------------------+\n",
      "|    id6| v1| v2|                v3|\n",
      "+-------+---+---+------------------+\n",
      "|5773276|341|792| 5585.354910999999|\n",
      "|2903102|356|973| 6205.401289000002|\n",
      "|2466341|267|736| 4515.288610000001|\n",
      "|2686046|281|769| 5316.997441000002|\n",
      "|7454645|312|887| 4921.975717999999|\n",
      "|6536815|335|916|       5886.131052|\n",
      "|1079126|286|741|5324.4377319999985|\n",
      "| 944877|282|817|5488.5830259999975|\n",
      "|2693701|316|812|       5648.669043|\n",
      "|3443772|334|965| 5950.841467999999|\n",
      "|2328897|317|874| 5503.581474999999|\n",
      "|1539817|222|646| 3475.920376999999|\n",
      "| 566250|321|809| 4961.607664000001|\n",
      "|8742933|244|703| 4397.223067000001|\n",
      "|4081353|322|777| 4908.233546999998|\n",
      "|2803042|263|749| 4180.598368999999|\n",
      "| 982174|341|897| 6163.637482999999|\n",
      "|5406874|299|795|       5459.568165|\n",
      "|2323132|342|967| 5555.607695999996|\n",
      "|7844955|298|739| 4931.196515999999|\n",
      "+-------+---+---+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select id6, sum(v1) as v1, sum(v2) as v2, sum(v3) as v3 from {df} group by id6\", df=df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29a67690-6915-4c49-86c8-c03f8ff2b73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select id6, sum(v1) as v1, sum(v2) as v2, sum(v3) as v3 from {df} group by id6\", df=df).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f52ad63-dc5e-4477-aef6-c8cfa10a3160",
   "metadata": {},
   "source": [
    "## Query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ec59350-ffc9-4eca-a87d-604f15b249f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 79:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------------------+------------------+\n",
      "|id4|id5|         median_v3|             sd_v3|\n",
      "+---+---+------------------+------------------+\n",
      "|  1|  1|        49.9667915|28.951202476533364|\n",
      "|  1|  3|         49.973412| 28.75385061525536|\n",
      "|  1|  4|50.044976500000004|28.871386653636858|\n",
      "|  1|  8|        49.6763525|28.870302332845846|\n",
      "|  1|  9|         49.967863| 28.85591006497422|\n",
      "|  1| 12|         50.059923|28.878182404369404|\n",
      "|  1| 13|50.030026500000005|28.913213008271043|\n",
      "|  1| 16|         49.744494|28.841951330631197|\n",
      "|  1| 19|         49.941295|28.846263544673924|\n",
      "|  1| 21|49.767773000000005|28.869396596703453|\n",
      "|  1| 24|         50.116194|28.881644688529512|\n",
      "|  1| 25|         50.125431|28.880724070335713|\n",
      "|  1| 27|          50.17253|28.893590675938803|\n",
      "|  1| 28|         49.934926|28.858709263195134|\n",
      "|  1| 31|49.900381499999995|28.850729085239575|\n",
      "|  1| 32|          49.88918|28.866283940438468|\n",
      "|  1| 33|         49.912413|28.792795893939132|\n",
      "|  1| 35|         49.978273|28.822689995800708|\n",
      "|  1| 36|         50.082134| 28.89761701384974|\n",
      "|  1| 37|         50.053458|28.920776448964144|\n",
      "+---+---+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select id4, id5, median(v3) as median_v3, stddev(v3) as sd_v3 from {df} group by id4, id5\", df=df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d4a5e06-12fc-4abf-941b-ade1686c73c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select id4, id5, median(v3) as median_v3, stddev(v3) as sd_v3 from {df} group by id4, id5\", df=df).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861c3378-087a-4dc5-959f-84077173a172",
   "metadata": {},
   "source": [
    "## Query 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "befb6a72-7fb3-4868-8279-fc162a303322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 92:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|         id3|range_v1_v2|\n",
      "+------------+-----------+\n",
      "|id0002654924|          4|\n",
      "|id0001975574|          4|\n",
      "|id0002470600|          4|\n",
      "|id0001698780|          4|\n",
      "|id0000058673|          4|\n",
      "|id0003895227|          4|\n",
      "|id0005293826|          4|\n",
      "|id0007581630|          4|\n",
      "|id0000651978|          4|\n",
      "|id0003454065|          4|\n",
      "|id0001755020|          4|\n",
      "|id0005409186|          4|\n",
      "|id0005802677|          4|\n",
      "|id0009759301|          4|\n",
      "|id0005675043|          4|\n",
      "|id0008654924|          4|\n",
      "|id0000248674|          4|\n",
      "|id0005200803|          4|\n",
      "|id0000784417|          4|\n",
      "|id0007793617|          4|\n",
      "+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select id3, max(v1)-min(v2) as range_v1_v2 from {df} group by id3\", df=df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d57582ac-507f-4504-b504-4d3d18517824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select id3, max(v1)-min(v2) as range_v1_v2 from {df} group by id3\", df=df).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa1512-145e-497c-9005-ac0a40fa6d99",
   "metadata": {},
   "source": [
    "## Query 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f13c159-1907-4127-9f41-21454bf02af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 105:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "|id6|largest2_v3|\n",
      "+---+-----------+\n",
      "|  2|  98.933402|\n",
      "|  2|  96.387642|\n",
      "|  4|  97.930795|\n",
      "|  4|  97.038094|\n",
      "|  5|  97.234212|\n",
      "|  5|  97.220159|\n",
      "|  8|    99.6065|\n",
      "|  8|  99.487874|\n",
      "| 12|  99.699698|\n",
      "| 12|  98.800794|\n",
      "| 14|  99.586843|\n",
      "| 14|  98.666442|\n",
      "| 15|   99.38758|\n",
      "| 15|    97.9149|\n",
      "| 16|  99.827275|\n",
      "| 16|  98.889332|\n",
      "| 17|  96.784773|\n",
      "| 17|  92.879215|\n",
      "| 18|  97.062454|\n",
      "| 18|  94.603703|\n",
      "+---+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select id6, largest2_v3 from (select id6, v3 as largest2_v3, row_number() over (partition by id6 order by v3 desc) as order_v3 from {df} where v3 is not null) sub_query where order_v3 <= 2\", df=df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8443ab04-c8db-48c5-b9ec-b6203a3f34af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.                 (0 + 2) / 2]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthew.powers/opt/miniconda3/envs/pyspark-340-delta-240/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/matthew.powers/opt/miniconda3/envs/pyspark-340-delta-240/lib/python3.9/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/Users/matthew.powers/opt/miniconda3/envs/pyspark-340-delta-240/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mselect id6, largest2_v3 from (select id6, v3 as largest2_v3, row_number() over (partition by id6 order by v3 desc) as order_v3 from \u001b[39;49m\u001b[38;5;132;43;01m{df}\u001b[39;49;00m\u001b[38;5;124;43m where v3 is not null) sub_query where order_v3 <= 2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pyspark-340-delta-240/lib/python3.9/site-packages/pyspark/sql/dataframe.py:1193\u001b[0m, in \u001b[0;36mDataFrame.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the number of rows in this :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   1172\u001b[0m \n\u001b[1;32m   1173\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m    3\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pyspark-340-delta-240/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pyspark-340-delta-240/lib/python3.9/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pyspark-340-delta-240/lib/python3.9/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pyspark-340-delta-240/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "spark.sql(\"select id6, largest2_v3 from (select id6, v3 as largest2_v3, row_number() over (partition by id6 order by v3 desc) as order_v3 from {df} where v3 is not null) sub_query where order_v3 <= 2\", df=df).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de486149-8c29-4807-a645-7b2c6733452c",
   "metadata": {},
   "source": [
    "## Query 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdad230-9bfa-4d23-9923-6ef7973dec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select id2, id4, pow(corr(v1, v2), 2) as r2 from {df} group by id2, id4\", df=df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9662d397-7dce-45bb-b034-7ebb29bcf351",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select id2, id4, pow(corr(v1, v2), 2) as r2 from {df} group by id2, id4\", df=df).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd7a903-6816-4c42-ac1c-b09dba59a2d5",
   "metadata": {},
   "source": [
    "## Query 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951f0a00-ea14-46c2-81c5-4a16fb4a530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select id1, id2, id3, id4, id5, id6, sum(v3) as v3, count(*) as count from {df} group by id1, id2, id3, id4, id5, id6\", df=df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efff0fa0-8e00-4857-b8b6-80c053328f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select id1, id2, id3, id4, id5, id6, sum(v3) as v3, count(*) as count from {df} group by id1, id2, id3, id4, id5, id6\", df=df).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898bac52-7950-4311-b64d-d292191650d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-340-delta-240",
   "language": "python",
   "name": "pyspark-340-delta-240"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
