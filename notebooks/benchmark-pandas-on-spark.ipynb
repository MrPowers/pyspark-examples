{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f5d529-bab9-49c4-9512-9e778c5cbc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import delta\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from delta import configure_spark_with_delta_pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c8373e-ca23-4e86-b54f-0845570d856e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/matthew.powers/opt/miniconda3/envs/pyspark-350-delta-310/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/matthew.powers/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/matthew.powers/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-e69e4287-6768-4b43-8716-c700dacb9d22;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.1.0 in central\n",
      "\tfound io.delta#delta-storage;3.1.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 108ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.1.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.1.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-e69e4287-6768-4b43-8716-c700dacb9d22\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/4ms)\n",
      "24/04/08 11:01:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "builder = (\n",
    "    pyspark.sql.SparkSession.builder.appName(\"MyApp\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.executor.memory\", \"10G\")\n",
    "    .config(\"spark.driver.memory\", \"25G\")\n",
    "    .config(\n",
    "        \"spark.sql.catalog.spark_catalog\",\n",
    "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "    )\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"2\")\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99896625-d364-4fca-9a3e-e48a0113fcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"OFF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c07da5-0dda-4b44-be67-42b6b7ba98fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthew.powers/opt/miniconda3/envs/pyspark-350-delta-310/lib/python3.9/site-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pyspark.pandas as ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6077e75-403f-4fa5-a767-d30efb40b223",
   "metadata": {},
   "source": [
    "## pandas on Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f991af7-306b-4194-8973-fa8a843ea7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthew.powers/opt/miniconda3/envs/pyspark-350-delta-310/lib/python3.9/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `read_parquet`, the default index is attached which can cause additional overhead.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
      "/Users/matthew.powers/opt/miniconda3/envs/pyspark-350-delta-310/lib/python3.9/site-packages/pyspark/pandas/groupby.py:893: FutureWarning: Default value of `numeric_only` will be changed to `False` instead of `True` in 4.0.0.\n",
      "  warnings.warn(\n",
      "[Stage 13:=====================================================>(226 + 3) / 229]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 v3\n",
      "id2                \n",
      "id058  1.004116e+07\n",
      "id082  9.989551e+06\n",
      "id083  1.000824e+07\n",
      "CPU times: user 120 ms, sys: 39.1 ms, total: 159 ms\n",
      "Wall time: 56.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = ps.read_parquet(\"/Users/matthew.powers/data/G1_1e9_1e2_0_0.parquet\")[\n",
    "    [\"id1\", \"id2\", \"v3\"]\n",
    "]\n",
    "res = df.query(\"id1 > 'id098'\").groupby(\"id2\").sum().head(3)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ae4a10-c2fb-476d-a9ba-bc43ebcd1d56",
   "metadata": {},
   "source": [
    "# pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a4d0e6a-957f-406e-878d-08705ba79584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.1 s, sys: 4.39 s, total: 30.5 s\n",
      "Wall time: 21.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>v3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id001</th>\n",
       "      <td>id094id094id094id094id094id094id094id094id094i...</td>\n",
       "      <td>505236.862575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id002</th>\n",
       "      <td>id094id094id094id094id094id094id094id094id094i...</td>\n",
       "      <td>511573.248652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id003</th>\n",
       "      <td>id094id094id094id094id094id094id094id094id094i...</td>\n",
       "      <td>503150.385213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id1             v3\n",
       "id2                                                                    \n",
       "id001  id094id094id094id094id094id094id094id094id094i...  505236.862575\n",
       "id002  id094id094id094id094id094id094id094id094id094i...  511573.248652\n",
       "id003  id094id094id094id094id094id094id094id094id094i...  503150.385213"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_parquet(\"/Users/matthew.powers/data/G1_1e9_1e2_0_0.parquet\")[\n",
    "    [\"id1\", \"id2\", \"v3\"]\n",
    "]\n",
    "df.query(\"id1 > 'id098'\").groupby(\"id2\").sum().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e651ee0-9581-4668-a794-4b4cb4fed68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d0035e-1256-43c2-ada3-15c0a2aa4168",
   "metadata": {},
   "source": [
    "## pandas with user optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cc7b2d9-8dfd-4089-9168-b9f1fb31649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 55s, sys: 18.9 s, total: 5min 14s\n",
      "Wall time: 4min 35s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>v3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id001</th>\n",
       "      <td>id100id099id099id099id100id100id099id100id100i...</td>\n",
       "      <td>9.995667e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id002</th>\n",
       "      <td>id099id100id100id100id100id099id099id100id099i...</td>\n",
       "      <td>1.000808e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id003</th>\n",
       "      <td>id099id100id099id100id100id100id099id099id099i...</td>\n",
       "      <td>9.984115e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id1            v3\n",
       "id2                                                                   \n",
       "id001  id100id099id099id099id100id100id099id100id100i...  9.995667e+06\n",
       "id002  id099id100id100id100id100id099id099id100id099i...  1.000808e+07\n",
       "id003  id099id100id099id100id100id100id099id099id099i...  9.984115e+06"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_parquet(\n",
    "    \"/Users/matthew.powers/data/G1_1e9_1e2_0_0.parquet\",\n",
    "    columns=[\"id1\", \"id2\", \"v3\"],\n",
    "    filters=[(\"id1\", \">\", \"id098\")],\n",
    "    engine=\"pyarrow\",\n",
    ")\n",
    "df.query(\"id1 > 'id098'\").groupby(\"id2\").sum().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a9aee9-2e70-48e6-af04-4054f443e0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000461"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd6fcccc-cc7f-412c-86f3-2a50a7e5aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7459920-5bab-42a5-aec7-7238c2b13e15",
   "metadata": {},
   "source": [
    "## pandas with incorrect user optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d36a3b34-baa8-4d34-a7b6-0500a7afaeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.9 s, sys: 4.57 s, total: 46.5 s\n",
      "Wall time: 6.59 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>v3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id1, v3]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_parquet(\n",
    "    \"/Users/matthew.powers/data/G1_1e9_1e2_0_0.parquet\",\n",
    "    columns=[\"id1\", \"id2\", \"v3\"],\n",
    "    filters=[(\"id1\", \"==\", \"id001\")],\n",
    "    engine=\"pyarrow\",\n",
    ")\n",
    "df.query(\"id1 > 'id098'\").groupby(\"id2\").sum().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ad672-4289-4ade-bc7d-d6aff0308099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-350-delta-310",
   "language": "python",
   "name": "pyspark-350-delta-310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
