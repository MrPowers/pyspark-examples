{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef787492-c753-4c7d-b923-64849f77aa8d",
   "metadata": {},
   "source": [
    "# Quinn Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60583d83-0356-4b4f-ac75-09577ca4c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import delta\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "import quinn\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9bcdbd5-d73d-44ee-b641-a21d643733bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = (\n",
    "    pyspark.sql.SparkSession.builder.appName(\"MyApp\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\n",
    "        \"spark.sql.catalog.spark_catalog\",\n",
    "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c7bf94-78cf-4d2e-9c5c-5fd39f163869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/matthew.powers/opt/miniconda3/envs/pyspark-everything/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/matthew.powers/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/matthew.powers/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-1a4a58c6-982d-4c9b-910b-7d25c11e5565;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.2.0 in central\n",
      "\tfound io.delta#delta-storage;2.2.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in central\n",
      ":: resolution report :: resolve 276ms :: artifacts dl 10ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.2.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.2.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-1a4a58c6-982d-4c9b-910b-7d25c11e5565\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/12ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/11 13:50:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = delta.configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad40a54-c3bf-4437-9b35-1976063875a0",
   "metadata": {},
   "source": [
    "## validate_presence_of_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c19f1e9c-6d8f-4314-a4d4-201e5002e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(\"bob\", 3), (\"sue\", 5)]).toDF(\"first_name\", \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2dc933f-e1d1-45d6-8d2b-e6db26b4247e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|first_name|age|\n",
      "+----------+---+\n",
      "|       bob|  3|\n",
      "|       sue|  5|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e8d5b0-6b55-419e-8de4-39d719dd5610",
   "metadata": {},
   "outputs": [],
   "source": [
    "quinn.validate_presence_of_columns(df, [\"first_name\", \"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2cad1ea-f838-47a3-91ef-d00ef83f5c6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "DataFrameMissingColumnError",
     "evalue": "The ['country'] columns are not included in the DataFrame with the following columns ['first_name', 'age']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataFrameMissingColumnError\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mquinn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_presence_of_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfirst_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcountry\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pyspark-everything/lib/python3.9/site-packages/quinn/dataframe_validator.py:21\u001b[0m, in \u001b[0;36mvalidate_presence_of_columns\u001b[0;34m(df, required_col_names)\u001b[0m\n\u001b[1;32m     16\u001b[0m error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{missing_col_names}\u001b[39;00m\u001b[38;5;124m columns are not included in the DataFrame with the following columns \u001b[39m\u001b[38;5;132;01m{all_col_names}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     17\u001b[0m     missing_col_names\u001b[38;5;241m=\u001b[39mmissing_col_names,\n\u001b[1;32m     18\u001b[0m     all_col_names\u001b[38;5;241m=\u001b[39mall_col_names\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_col_names:\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataFrameMissingColumnError(error_message)\n",
      "\u001b[0;31mDataFrameMissingColumnError\u001b[0m: The ['country'] columns are not included in the DataFrame with the following columns ['first_name', 'age']"
     ]
    }
   ],
   "source": [
    "quinn.validate_presence_of_columns(df, [\"first_name\", \"age\", \"country\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad53f63-4721-4e20-b3ce-85c7e4e6cd44",
   "metadata": {},
   "source": [
    "## validate_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63cfcfd-6dfa-4b40-a8f9-c11394e1c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(\"bob\", 3), (\"sue\", 5)]).toDF(\"first_name\", \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c25770b-9ad7-4f1a-beb0-afe0c7ae3756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|first_name|age|\n",
      "+----------+---+\n",
      "|       bob|  3|\n",
      "|       sue|  5|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b088325-a2ce-4aa1-be87-66aafc7cb40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89fec115-73be-4dfb-b135-d4f78e5269af",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_schema = StructType(\n",
    "    [\n",
    "        StructField(\"first_name\", StringType(), True),\n",
    "        StructField(\"age\", LongType(), True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f43f053d-4e57-42cb-8a75-93c258ae3c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "quinn.validate_schema(df, matching_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "124e070a-fd98-4584-9ef3-ed45e462d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatched_schema = StructType(\n",
    "    [\n",
    "        StructField(\"some_whatever\", IntegerType(), True),\n",
    "        StructField(\"age\", LongType(), True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb47fa31-72cf-4a77-9b8c-aac971b36890",
   "metadata": {},
   "outputs": [
    {
     "ename": "DataFrameMissingStructFieldError",
     "evalue": "The [StructField('some_whatever', IntegerType(), True)] StructFields are not included in the DataFrame with the following StructFields StructType([StructField('first_name', StringType(), True), StructField('age', LongType(), True)])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataFrameMissingStructFieldError\u001b[0m          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mquinn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmismatched_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pyspark-everything/lib/python3.9/site-packages/quinn/dataframe_validator.py:32\u001b[0m, in \u001b[0;36mvalidate_schema\u001b[0;34m(df, required_schema)\u001b[0m\n\u001b[1;32m     27\u001b[0m error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{missing_struct_fields}\u001b[39;00m\u001b[38;5;124m StructFields are not included in the DataFrame with the following StructFields \u001b[39m\u001b[38;5;132;01m{all_struct_fields}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     28\u001b[0m     missing_struct_fields\u001b[38;5;241m=\u001b[39mmissing_struct_fields,\n\u001b[1;32m     29\u001b[0m     all_struct_fields\u001b[38;5;241m=\u001b[39mall_struct_fields\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_struct_fields:\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataFrameMissingStructFieldError(error_message)\n",
      "\u001b[0;31mDataFrameMissingStructFieldError\u001b[0m: The [StructField('some_whatever', IntegerType(), True)] StructFields are not included in the DataFrame with the following StructFields StructType([StructField('first_name', StringType(), True), StructField('age', LongType(), True)])"
     ]
    }
   ],
   "source": [
    "quinn.validate_schema(df, mismatched_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b642b71c-7e7f-497e-ab71-c3d6b7e0c569",
   "metadata": {},
   "source": [
    "## validate_absence_of_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c2c91d-30d2-4d14-9c09-72bdd2f76d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(\"bob\", 3), (\"sue\", 5)]).toDF(\"first_name\", \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27019ac-5539-422b-b9fb-cfd86b7c8bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|first_name|age|\n",
      "+----------+---+\n",
      "|       bob|  3|\n",
      "|       sue|  5|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f95484a-cbfb-4d23-8a32-f8bf02ab4133",
   "metadata": {},
   "outputs": [],
   "source": [
    "quinn.validate_absence_of_columns(df, [\"favorite_color\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dffcc31-7db9-4ca2-8cc9-86e03cb6e936",
   "metadata": {},
   "outputs": [
    {
     "ename": "DataFrameProhibitedColumnError",
     "evalue": "The ['age'] columns are not allowed to be included in the DataFrame with the following columns ['first_name', 'age']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataFrameProhibitedColumnError\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mquinn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_absence_of_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pyspark-everything/lib/python3.9/site-packages/quinn/dataframe_validator.py:43\u001b[0m, in \u001b[0;36mvalidate_absence_of_columns\u001b[0;34m(df, prohibited_col_names)\u001b[0m\n\u001b[1;32m     38\u001b[0m error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{extra_col_names}\u001b[39;00m\u001b[38;5;124m columns are not allowed to be included in the DataFrame with the following columns \u001b[39m\u001b[38;5;132;01m{all_col_names}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     39\u001b[0m     extra_col_names\u001b[38;5;241m=\u001b[39mextra_col_names,\n\u001b[1;32m     40\u001b[0m     all_col_names\u001b[38;5;241m=\u001b[39mall_col_names\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_col_names:\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataFrameProhibitedColumnError(error_message)\n",
      "\u001b[0;31mDataFrameProhibitedColumnError\u001b[0m: The ['age'] columns are not allowed to be included in the DataFrame with the following columns ['first_name', 'age']"
     ]
    }
   ],
   "source": [
    "quinn.validate_absence_of_columns(df, [\"age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380d820a-a03e-47e5-96e1-c8b9dea76622",
   "metadata": {},
   "source": [
    "## Schema safe appends - need to make quinn better to make this flow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6d8df07-c510-4916-ac40-f916a271db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(\"bob\", 3), (\"sue\", 5)]).toDF(\"first_name\", \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c72ac06d-4cf8-449e-9052-33a400d4620d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|first_name|age|\n",
      "+----------+---+\n",
      "|       bob|  3|\n",
      "|       sue|  5|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c09d6ee-412e-4898-b5ca-764b9fedb6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"parquet\").save(\"tmp/parquet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e405e51-ec58-4685-8327-33c14d5fc032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|first_name|age|\n",
      "+----------+---+\n",
      "|       sue|  5|\n",
      "|       bob|  3|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"parquet\").load(\"tmp/parquet1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00cdd44c-55b1-4835-883a-07837919ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_append_df = spark.createDataFrame([(\"usa\", 99), (\"china\", 66)]).toDF(\n",
    "    \"country\", \"age\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fa6c5f0-dca4-4830-a768-618f7879f757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('country', StringType(), True), StructField('age', LongType(), True)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_append_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "048600b7-db9b-4ef6-aa8d-3000c76e3540",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (664740600.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[33], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    bad_append_df.write.format(\"parquet\").mode(\"append\").save(\"tmp/parquet1\")\u001b[0m\n\u001b[0m                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "if quinn.validate_schema(df, bad_append_df.schema):\n",
    "    bad_append_df.write.format(\"parquet\").mode(\"append\").save(\"tmp/parquet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1376c71-5521-4b43-a1f5-fd34b7842cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_append_df = spark.createDataFrame([(\"donald\", 77), (\"sergio\", 44)]).toDF(\n",
    "    \"first_name\", \"age\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb18fb83-3dff-4519-b8a3-632b6e76dc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|first_name|age|\n",
      "+----------+---+\n",
      "|    donald| 77|\n",
      "|    sergio| 44|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "good_append_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742efd0c-c065-41f9-986b-1ec00756bdb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "913f05ec-b81c-482a-be63-e06963a0e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if quinn.validate_schema(df, good_append_df.schema):\n",
    "    good_append_df.write.format(\"parquet\").mode(\"append\").save(\"tmp/parquet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a8b65e3-5327-4b7c-a646-1cc44c8990d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|first_name|age|\n",
      "+----------+---+\n",
      "|       bob|  3|\n",
      "|       sue|  5|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"parquet\").load(\"tmp/parquet1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f29839-bb1d-429d-9555-679e274b0fb6",
   "metadata": {},
   "source": [
    "## create_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9e22310-d3bb-4996-9a38-71b3200a55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quinn.extensions import create_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b60bd185-d05c-40e3-8509-8f0535151e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.create_df(\n",
    "    [(\"jose\", \"a\"), (\"li\", \"b\"), (\"sam\", \"c\")],\n",
    "    [(\"name\", StringType(), False), (\"blah\", StringType(), True)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96097cf6-609a-47ea-8ce8-dfbfd8aefcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|name|blah|\n",
      "+----+----+\n",
      "|jose|   a|\n",
      "|  li|   b|\n",
      "| sam|   c|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7da282b1-375d-4444-8e19-5e883235beba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = false)\n",
      " |-- blah: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b7871d4-f218-4988-be04-527403b3e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(\"jose\", \"a\"), (\"li\", \"b\"), (\"sam\", \"c\")]).toDF(\n",
    "    \"name\", \"blah\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27dd1afd-0ac6-4dc5-8358-77c9c829fb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|name|blah|\n",
      "+----+----+\n",
      "|jose|   a|\n",
      "|  li|   b|\n",
      "| sam|   c|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cfd0483-27a7-492c-af60-d78beb306c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- blah: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ffb1d8-10ed-4464-9e7d-ea9c19c0ea1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## create-df2: Manually specifying schemas can be tedious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16492137-2750-4aa6-b5c3-dcc0d2539907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    data=[(\"jose\", \"a\"), (\"li\", \"b\"), (\"sam\", \"c\")],\n",
    "    schema=StructType(\n",
    "        [\n",
    "            StructField(\"name\", StringType(), False),\n",
    "            StructField(\"blah\", StringType(), True),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fb04b01-22a9-4e03-be2a-cdb7ca74b0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|name|blah|\n",
      "+----+----+\n",
      "|jose|   a|\n",
      "|  li|   b|\n",
      "| sam|   c|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ece76620-6082-447b-be6b-84d3f601bf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = false)\n",
      " |-- blah: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9dd5d4f-ed78-4a43-8123-a58c597e568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quinn.extensions import create_df\n",
    "\n",
    "df = spark.create_df(\n",
    "    [(\"jose\", \"a\"), (\"li\", \"b\"), (\"sam\", \"c\")],\n",
    "    [(\"name\", StringType(), False), (\"blah\", StringType(), True)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6353d322-e47e-4c34-a28e-454bdf479405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|name|blah|\n",
      "+----+----+\n",
      "|jose|   a|\n",
      "|  li|   b|\n",
      "| sam|   c|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcd3c3c4-673f-41fe-8714-88971eef9eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = false)\n",
      " |-- blah: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1b92aa-3c66-4a1e-9256-1859f51a7ee6",
   "metadata": {},
   "source": [
    "## single_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e4b3996-8063-4fdd-af5c-6c5e67641e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [(\"This  is a   thing.\",), (\"More weird    spacing.\",)]\n",
    ").toDF(\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f5fa776-c5a6-4cfd-96fc-e40102a61b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|words                 |\n",
      "+----------------------+\n",
      "|This  is a   thing.   |\n",
      "|More weird    spacing.|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3b75c420-f4b4-4ff1-9b40-0c93412ddaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------------+\n",
      "|words                 |words_clean        |\n",
      "+----------------------+-------------------+\n",
      "|This  is a   thing.   |This is a thing.   |\n",
      "|More weird    spacing.|More weird spacing.|\n",
      "+----------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"words_clean\", quinn.single_space(F.col(\"words\"))).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51276b18-e914-4614-b560-51597cae12cb",
   "metadata": {},
   "source": [
    "## remove_all_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca8ba16-ec86-4c97-8edc-b8aca8b5af9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7889a78b-a10f-4caf-9dac-67f5a16eda88",
   "metadata": {},
   "source": [
    "## anti_trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455784e3-3839-433d-9ad3-df9ebba6623e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a54f8f9-ecd4-43d4-b2df-cba07e9935f4",
   "metadata": {},
   "source": [
    "## remove_non_word_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e7e3d7e-e652-4121-9eb2-3ea022e3fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(\"si%$#@!#$!@#mpsons\",), (\"I|lIke|CAts\",)]).toDF(\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6ec8069f-c686-4594-bc72-5bc757c15f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|words             |\n",
      "+------------------+\n",
      "|si%$#@!#$!@#mpsons|\n",
      "|I|lIke|CAts       |\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71921a86-995e-4396-b973-3d694fdd01dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------+\n",
      "|words             |words_clean|\n",
      "+------------------+-----------+\n",
      "|si%$#@!#$!@#mpsons|simpsons   |\n",
      "|I|lIke|CAts       |IlIkeCAts  |\n",
      "+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"words_clean\", quinn.remove_non_word_characters(F.col(\"words\"))).show(\n",
    "    truncate=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba7e444-2589-4aa7-803f-730d78a3e29b",
   "metadata": {},
   "source": [
    "## column_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4fb7acd-ae00-461e-8f8a-ffe1fbcececf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(\"bob\", 3), (\"sue\", 5)]).toDF(\"first_name\", \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8657b435-0ba0-4464-a626-0208e58e472e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|first_name|age|\n",
      "+----------+---+\n",
      "|       bob|  3|\n",
      "|       sue|  5|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "955ca754-780d-4607-a4a4-181f6d644f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quinn.column_to_list(df, \"age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89fcb88-7390-4a20-839d-88e91ae64382",
   "metadata": {},
   "source": [
    "## two_columns_to_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ddcb834f-bf44-4e81-8a79-5f5d9c6d23dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(34, \"crazydude\"), (99, \"firelover\")]).toDF(\n",
    "    \"id\", \"username\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d7716bfa-2633-47a8-9069-2469b6bf9bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id| username|\n",
      "+---+---------+\n",
      "| 34|crazydude|\n",
      "| 99|firelover|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "623130f1-d78d-4f29-8b36-968553f22471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{34: 'crazydude', 99: 'firelover'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quinn.two_columns_to_dictionary(df, \"id\", \"username\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6f477-6c29-4e26-9645-a3566749be4f",
   "metadata": {},
   "source": [
    "## to_list_of_dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "896e1f7a-b494-4ef0-ba99-c8e6cbe35e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de995796-50fd-423a-81ad-7b24143ff8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a31fbf4b-d3d8-412c-8493-33a09514a9ce",
   "metadata": {},
   "source": [
    "## show_output_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bbec3e25-e2cf-44e3-8d3b-d687e6530985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_str = \"\"\"+---+---------+\n",
    "| id| username|\n",
    "+---+---------+\n",
    "| 34|crazydude|\n",
    "| 99|firelover|\n",
    "+---+---------+\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7356a4ca-7202-4db4-b305-c68f2ff93297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = quinn.show_output_to_df(df_str, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "79913fc7-cc04-4c58-86c7-601972773a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id| username|\n",
      "+---+---------+\n",
      "| 34|crazydude|\n",
      "| 99|firelover|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e94a6-fb54-4c67-9f96-49fde5b360d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
