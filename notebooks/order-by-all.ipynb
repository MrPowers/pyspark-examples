{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c645f055-b38d-4b33-8b7b-c331ee2398b6",
   "metadata": {},
   "source": [
    "# ORDER BY ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "241ff2cd-7a50-41d9-a86a-fa640d986da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe215762-e6e2-4b09-a942-87ab5821ddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/04 08:39:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"demo\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15d70eb7-7a5f-4daa-a365-2dc6372dfd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_df = spark.createDataFrame(\n",
    "    [\n",
    "        (datetime.date(2020, 1, 20), 8),\n",
    "        (datetime.date(2021, 5, 17), 4),\n",
    "        (datetime.date(2020, 1, 20), 3),\n",
    "    ],\n",
    "    [\"the_date\", \"some_num\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ba3c5bf-6413-45d8-b6f0-63198ff0ee5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|  the_date|some_num|\n",
      "+----------+--------+\n",
      "|2020-01-20|       8|\n",
      "|2021-05-17|       4|\n",
      "|2020-01-20|       3|\n",
      "+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "some_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a20355e-54c1-4d52-be47-6a74d269938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_df.createOrReplaceTempView(\"some_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "620679b2-52ed-43b7-bbe7-ff5413a98a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|  the_date|some_num|\n",
      "+----------+--------+\n",
      "|2020-01-20|       3|\n",
      "|2020-01-20|       8|\n",
      "|2021-05-17|       4|\n",
      "+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from some_table ORDER BY ALL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb07bed2-a2e0-428f-bbba-531dc84cb80b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-340-delta-240",
   "language": "python",
   "name": "pyspark-340-delta-240"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
